{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sashwot10/5CS037/blob/main/Worksheet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " TO DO TASK 1:\n",
        "1. Read and Observe the Dataset.\n",
        "2. Print top(5) and bottom(5) of the dataset {Hint: pd.head and pd.tail}.\n",
        "3. Print the Information of Datasets. {Hint: pd.info}.\n",
        "4. Gather the Descriptive info about the Dataset. {Hint: pd.describe}\n",
        " 5. Split your data into Feature (X) and Label (Y)."
      ],
      "metadata": {
        "id": "AKMbLcq3WgIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaNiPLGaFXoY",
        "outputId": "84aee4d9-2c19-4f33-93fd-3537b5d873a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sWYI-6UWbAr",
        "outputId": "36470a4a-6d46-412d-ce54-adafff5a67a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "     Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Data/student-2.csv\")\n",
        "\n",
        "print(dataset.head())#this prints top 5 rows\n",
        "print(dataset.tail())#thsi prints bottom 5 rows\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.info())#this gives every information of dataset like Column names, data types, non-null counts\n",
        "print(dataset.describe())#this gives description like mean median SD\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXoS3YG8YVqK",
        "outputId": "5d78fcad-8d4c-4ce2-fbfe-4eca02c72af2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "None\n",
            "              Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data split gareko into x and y\n",
        "X = dataset[['Math', 'Reading']].values#feature\n",
        "Y = dataset['Writing'].values#target\n"
      ],
      "metadata": {
        "id": "YeXNIbEFY2_9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 2:\n",
        "1. To make the task easier - letâ€™s assume there is no bias or intercept.\n",
        "2. Create the given matrix\n",
        "3. Note: The feature matrix described above does not include a column of 1s, as it assumes the\n",
        "absence of a bias term in the model.\n"
      ],
      "metadata": {
        "id": "Q_gT8taVZrEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of Y:\", Y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HktCFkrtZkjb",
        "outputId": "fe3402b8-bfbc-4487-b9b0-e0adc9bfd1c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1000, 2)\n",
            "Shape of Y: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 3:\n",
        "1. Split the dataset into training and test sets.\n",
        "2. You can use an 80-20 or 70-30 split, with 80% (or 70%) of the data used for training and the rest\n",
        "for testing."
      ],
      "metadata": {
        "id": "GqptAKS8bL91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#80% DATA TRAIN\n",
        "#20% DATA TEST\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "FS5tlMfDajUn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 4:\n",
        "\n",
        "Building a Cost Function\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ifAbrwC5fZP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(X, Y, W):\n",
        "    \"\"\"\n",
        "    Computes Mean Squared Error Cost\n",
        "    \"\"\"\n",
        "    n = len(Y)\n",
        "    Y_pred = np.dot(X, W)\n",
        "    cost = (1 / (2 * n)) * np.sum((Y_pred - Y) ** 2)\n",
        "    return cost"
      ],
      "metadata": {
        "id": "Q3Yl9DrkbXHc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 5:\n",
        "\n",
        "Make sure your code at TO DO TASK 4 passed the following test case\n",
        "\n",
        "Testing a Cost Function:"
      ],
      "metadata": {
        "id": "rZQBMOE1fxSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "Y_test = np.array([3, 7, 11])\n",
        "W_test = np.array([1, 1])\n",
        "\n",
        "cost = cost_function(X_test, Y_test, W_test)\n",
        "\n",
        "if cost == 0:\n",
        "    print(\"let's move further\")\n",
        "else:\n",
        "    print(\"something is wrong\")\n",
        "\n",
        "print(\"result of cost function: \", cost)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30tQB0SsfrjW",
        "outputId": "800f7fa2-9c00-4667-de0b-da71b563966e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "let's move further\n",
            "result of cost function:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 6\n",
        "\n",
        "Implement your code for Gradient Descent; Either fill the following code or write your own\n",
        "\n",
        "Gradient Descent from Scratch"
      ],
      "metadata": {
        "id": "MFaF4PoPgYt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    cost_history = []\n",
        "    m = len(Y)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        #PRDEICTION Y\n",
        "        Y_pred = np.dot(X, W)\n",
        "\n",
        "        #ERROR CALC\n",
        "        loss = Y_pred - Y\n",
        "\n",
        "        #GRADIENT DESCENT\n",
        "        dw = (1 / m) * np.dot(X.T, loss)\n",
        "\n",
        "        #UPDATING WEIGHTS\n",
        "        W = W - alpha * dw\n",
        "\n",
        "        #COST FUNC-N\n",
        "        cost = cost_function(X, Y, W)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return W, cost_history\n",
        "#THIS FUNC-N PROVIDES THE LIST OF COST VALUES OVER TIME"
      ],
      "metadata": {
        "id": "mXV9OEmzgK5J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 7:\n",
        "\n",
        "Make sure following Test Case is passed by your code from To - Do - 6\n",
        "\n",
        "\n",
        " Gradient Descent\n",
        "Implementation:"
      ],
      "metadata": {
        "id": "PKDgHSLFhYyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "X = np.random.rand(100, 3)\n",
        "Y = np.random.rand(100)\n",
        "W = np.random.rand(3)\n",
        "\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "final_params, cost_history = gradient_descent(X, Y, W, alpha, iterations)\n",
        "\n",
        "print(\"Final Parameters:\", final_params)\n",
        "print(\"Cost History:\", cost_history[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07T57b-OgvzU",
        "outputId": "75abbfe2-9754-405d-9e5a-13a767922f3a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Parameters: [0.20551667 0.54295081 0.10388027]\n",
            "Cost History: [np.float64(0.10711197094660153), np.float64(0.10634880599939901), np.float64(0.10559826315680618), np.float64(0.10486012948320558), np.float64(0.1041341956428534), np.float64(0.10342025583900626), np.float64(0.1027181077540776), np.float64(0.1020275524908062), np.float64(0.10134839451441931), np.float64(0.1006804415957737)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 8:\n",
        "\n",
        "Implementation of RMSE in the Code - Complete the following code or write your own:\n",
        "\n",
        "Code for RMSE:"
      ],
      "metadata": {
        "id": "bXJKlcGOhlZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "    return np.sqrt(np.mean((Y - Y_pred) ** 2))"
      ],
      "metadata": {
        "id": "UHMgI7o0hNQJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 9\n",
        "\n",
        "code for r2 loss:"
      ],
      "metadata": {
        "id": "RsS37QN1ikkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def r2(Y, Y_pred):\n",
        "    mean_y = np.mean(Y)\n",
        "    ss_tot = np.sum((Y - mean_y) ** 2)\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "    return r2"
      ],
      "metadata": {
        "id": "OLpKvlXuhujX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 10\n",
        "\n",
        "We will define a function that:\n",
        "1. Loads the data and splits it into training and test sets.\n",
        "2. Prepares the feature matrix (X) and target vector (Y).\n",
        "3. Defines the weight matrix (W) and initializes the learning rate and number of iterations.\n",
        "4. Calls the gradient descent function to learn the parameters.\n",
        "5. Evaluates the model using RMSE and R2."
      ],
      "metadata": {
        "id": "shs72XTVjRUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    # 1. Load the dataset\n",
        "    data = pd.read_csv(\"/content/drive/MyDrive/Data/student-2.csv\")\n",
        "\n",
        "    # 2. Split the data into features (X) and target (Y)\n",
        "    # X contains Math and Reading marks\n",
        "    # Y contains Writing marks\n",
        "    X = data[['Math', 'Reading']].values\n",
        "    Y = data['Writing'].values\n",
        "\n",
        "    # 3. Split the data into training and testing sets (80% training, 20% testing)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # 4. Initialize weights, learning rate, and number of iterations\n",
        "    W = np.zeros(X_train.shape[1])\n",
        "    alpha = 0.00001\n",
        "    iterations = 1000\n",
        "\n",
        "    # 5. Train the model using Gradient Descent\n",
        "    W_optimal, cost_history = gradient_descent(\n",
        "        X_train, Y_train, W, alpha, iterations\n",
        "    )\n",
        "\n",
        "    #Make predictions on test data\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "   #RESULT\n",
        "    print(\"Final Weights:\", W_optimal)\n",
        "    print(\"Cost History (First 10):\", cost_history[:10])\n",
        "    print(\"RMSE:\", rmse(Y_test, Y_pred))\n",
        "    print(\"R2:\", r2(Y_test, Y_pred))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5IswdwnjQb6",
        "outputId": "4babd1b3-1f5e-483d-dcac-4c9b9f052618"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.34811659 0.64614558]\n",
            "Cost History (First 10): [np.float64(2013.165570783755), np.float64(1640.286832599692), np.float64(1337.0619994901588), np.float64(1090.4794892850578), np.float64(889.9583270083234), np.float64(726.8940993009545), np.float64(594.2897260808594), np.float64(486.4552052951635), np.float64(398.7634463599484), np.float64(327.4517147324688)]\n",
            "RMSE: 5.2798239764188635\n",
            "R2: 0.8886354462786421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO TASK 11\n",
        "\n",
        "Present your finding:\n",
        "1. Did your Model Overfitt, Underfitts, or performance is acceptable.\n",
        "2. Experiment with different value of learning rate, making it higher and lower, observe the result."
      ],
      "metadata": {
        "id": "TX-yrIgbkGQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Model Performance:\n",
        "\n",
        "The model performance is acceptable. It is neither overfitting nor underfitting.\n",
        "\n",
        "\n",
        "2. Learning Rate Experiment:\n",
        "\n",
        "\n",
        "Lower learning rate: Slower convergence\n",
        "\n",
        "\n",
        "Higher learning rate: Faster but may become unstable"
      ],
      "metadata": {
        "id": "xl1qx3R7kX9W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-4qjBPQkYgh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}